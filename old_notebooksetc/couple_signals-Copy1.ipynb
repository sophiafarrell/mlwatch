{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ec63f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reading the ROOT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52ba670-fb9b-4d7c-b66d-3e611b20ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(\"./do_imports.py\").read())\n",
    "\n",
    "def get_paired_data(data):\n",
    "    next_ts = data.timestamp[1:]\n",
    "    next_ts = ak.concatenate([next_ts, 0])\n",
    "\n",
    "    condition_1 = next_ts - data.timestamp<600\n",
    "    condition_2 = next_ts - data.timestamp>0\n",
    "    condition_3 = data.dt_next_us < 600\n",
    "\n",
    "    both = condition_1 * condition_2 * condition_3\n",
    "\n",
    "    first_of_two = ak.where(both)[0]\n",
    "    signal1 = data[first_of_two]\n",
    "    signal2 = data[first_of_two+1]\n",
    "    \n",
    "    return signal1, signal2\n",
    "ibd = ak.from_json('data/ibd.json')\n",
    "fastn = ak.from_json('data/fastn.json')\n",
    "\n",
    "fn0, fn1 = get_paired_data(fastn)\n",
    "ibd0, ibd1 = get_paired_data(ibd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "0ba3544f-a08c-4265-bfaa-2fdf2619474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = [ibd0, fn0]\n",
    "samples = min([len(i) for i in selection])\n",
    "first_signal = ak.concatenate([fn0[:samples], ibd0[:samples]])\n",
    "second_signal = ak.concatenate([fn1[:samples], ibd1[:samples]])\n",
    "y = np.where(first_signal.code==2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "9bf5341e-5a95-4784-859d-e283ff63b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainidx, testidx = train_test_split(np.arange(len(y)), test_size=.25, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "b4ab3e19-5863-4029-b392-87f36507ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test_water_og.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "1bc4b5d9-1bb2-4098-a251-6614b8b91b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dict(ev1 = first_signal[trainidx],\n",
    "             ev2 = second_signal[trainidx],\n",
    "             y = y[trainidx]\n",
    "            )\n",
    "test = dict(ev1 = first_signal[testidx],\n",
    "             ev2 = second_signal[testidx],\n",
    "             y = y[testidx]\n",
    "            )\n",
    "\n",
    "# pickle.dump(test, open( \"./data/test_water_og.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76ddc5b2-99dd-4197-b333-bc4c2149af77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fastn = uproot.open('data/fastn_water.root'+':data')\n",
    "fastn= fastn.arrays(library='awkward')\n",
    "\n",
    "# Time-sort all the data arrays for recurrent/sequential purposes. \n",
    "for j, data in enumerate([fastn]):\n",
    "    print('set %i'%(j))\n",
    "    args = ak.argsort(data['hittime'])\n",
    "    for key in ['hittime', 'pmtcharge', 'channel']:\n",
    "        data[key] = data[key][args]\n",
    "        \n",
    "# Get rid of the first and last events of each run \n",
    "fastn = fastn[fastn['inner_hit_prev']>0]\n",
    "fastn = fastn[fastn['inner_hit_next']>0]\n",
    "fastn = fastn[fastn['dt_prev_us']>0]\n",
    "ak.to_json(fastn, 'data/fastn_water.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d37937-a0a5-4f22-aa03-28dde7216595",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(\"./do_imports.py\").read())\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "f526f981-42e8-40a1-8d97-6643dc1ec53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_results import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b3de20-5496-45d3-b6a0-e9353eebeff2",
   "metadata": {},
   "source": [
    "We want where quicknext<500 us (so another prompt follows) and the subid==1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab2244b-f00b-4757-bd08-f48f4b383363",
   "metadata": {},
   "source": [
    "What if we boost our fast-neutron stamps by not requiring it to be the first event (so tri-neutron events recorded too but in pairs?) \n",
    "<br>\n",
    "Obviously this is not realistic since we'd veto these by having 3, but we can at least pretend they're di-neutrons! \n",
    "\n",
    "Edit: the next code is already doing that! We gain 1149/5500 of the stats from that trick, which is necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9dd043af-2f7e-4b98-a0ea-e97813aeb483",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test_water_og.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d170e49f-ab33-4692-80e3-ab291b69af79",
   "metadata": {},
   "source": [
    "### Prep data for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e0487f1-4d46-496b-9432-080f913f86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from batched_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "e3ab10d0-ce0b-4df3-9b71-3603f4c0393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = DatSequence('test_water_og', batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "9de83697-12a3-4403-b557-f57ac91d89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = val.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0929c-6580-45d8-9caa-8027dce3e54b",
   "metadata": {},
   "source": [
    "The error is between first_b and X_test1 at the 2nd index, not the 0 or 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "a4f46a9e-8477-42ea-ba45-120bf0c5ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bins1 = ak.values_astype((first_signal.hittime-300)/div_factor, np.int32)\n",
    "new_bins2 = ak.values_astype((second_signal.hittime-300)/div_factor, np.int32)\n",
    "first = np.zeros((len(first_signal), npmts, nbins), dtype=np.float32)\n",
    "second = np.zeros_like(first)\n",
    "\n",
    "for i in range(0, len(first_signal)):\n",
    "    first[i, first_signal.channel[i], new_bins1[i]]=first_signal.pmtcharge[i]\n",
    "    second[i, second_signal.channel[i], new_bins2[i]]=second_signal.pmtcharge[i]\n",
    "    \n",
    "# X_train1, X_test1, X_train2, X_test2, y_train, y_test = train_test_split(\n",
    "#     first, second, y,\n",
    "#     test_size=0.25, random_state=43\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "9017c242-e06a-41a4-ab56-267aa9babf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set 1 of 2\n",
      "set 2 of 2\n"
     ]
    }
   ],
   "source": [
    "selection = [ibd0, fn0]\n",
    "samples = min([len(i) for i in selection])\n",
    "\n",
    "npmts = 2330\n",
    "timetot = 1500 #ns \n",
    "tres = 10 # ns \n",
    "div_factor = tres \n",
    "nbins = int(timetot/tres)\n",
    "size = samples * len(selection)\n",
    "y = np.array([]) \n",
    "\n",
    "first = np.zeros((size, npmts, nbins), dtype=np.float32)\n",
    "second = np.zeros_like(first)\n",
    "\n",
    "data_to_manipulate = [[fn0[:samples], fn1[:samples]], [ibd0[:samples], ibd1[:samples]]]\n",
    "for d, (signal1, signal2) in enumerate(data_to_manipulate):\n",
    "    assert ak.all(signal1.code==signal2.code)\n",
    "    print('set %i of %i'%(d+1, len(data_to_manipulate)))\n",
    "    \n",
    "    new_bins1 = ak.values_astype((signal1.hittime-300)/div_factor, np.int32)\n",
    "    new_bins2 = ak.values_astype((signal2.hittime-300)/div_factor, np.int32)\n",
    "    \n",
    "    for i in range(0, samples):\n",
    "        first[d*samples+i, signal1.channel[i], new_bins1[i]]=signal1.pmtcharge[i]\n",
    "        second[d*samples+i, signal2.channel[i], new_bins2[i]]=signal2.pmtcharge[i]\n",
    "    y=np.append(y, d*np.ones(samples))\n",
    "    \n",
    "    if d==0: bins_out = new_bins1\n",
    "    else: bins_out = ak.concatenate([bins_out, new_bins1])\n",
    "    \n",
    "X_train1, X_test1, X_train2, X_test2, y_train, y_test = train_test_split(\n",
    "    first, second, y,\n",
    "    test_size=0.25, random_state=43\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-sjf37]",
   "language": "python",
   "name": "conda-env-.conda-sjf37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
